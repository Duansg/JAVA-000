### 笔记
    1.丢弃订单:最早期，量太大扛不住，直接前端随机reject一些，返回给抢单失败，简 单粗暴，但是有效，比如10万人抢100个iPhone，只要能提前预测有大概1万以上的人 参与(通过资格确认、报名等方式收集信息)，那么直接请求进来以后随机挡回去 99%的流量都没有啥问题。
    2.优化吞吐:中间有段时间，提前准备一大批机器，服务化、分库分表搞定后端性能， 让前端业务可以加一定量的机器，然后搞稳定性，依赖关系，容量规划，做弹性，提升 吞吐量。
    3.异步队列:然后就是使用可堆积的消息队列或者内存消息队列了，如果抢单具有强顺 序，那么先都进队列，然后拿前N(就是库存数)个出来平滑处理，剩下的所有都可以 作为失败进行批处理了，甚至还可以做一个定长的队列，再往里写直接提示失败。队列 把并发变成串行，从而去掉了锁。
    技术上有哪些优化办法
    4.内存分配:一些具体的业务，也会考虑预热，提前在每个机器节点内存分配好库存数 量，然后直接在内存里处理自己的库存数即可，这样可能也会在极端情况下啊，
    5.拆分扩展:针对不同类型、不同商家、不同来源的商品，部署不同的前端促销集群， 这样就把压力分散开了。具体到每个商家，其实量就不大了，双十一销售第一名的商家， 并发也不是特别高。
    6.服务降级:越重要的抢单，大家越关心自己有没有抢到，而不是特别在意订单立即处 理完，也就是说，下单占到位置比处理完成订单要更有价值。比如12306春运抢票，只 要告诉用户你抢到了票，但是预计1个小时后订单才会处理完，用户有这个明确预期， 就可以了，用户不会立马使用这张票，也不会在意1分钟内处理完还是1小时处理完。
    需要注意的是其中部分模式会导致销售不足或者超卖，销售不足可以从抢购里加一些名 单补发，也可以加一轮秒杀。超卖比较麻烦，所以一般会多备一点货，比如抢100个 iPhone，提前准备105个之类的，也会证明在实际操作里非常有价值。
### 限流
    Nginx 限流，后段令牌桶算法等
    根据能够唯一确定用户的标志，对用户请求去重
    将库存预分配到缓存，在缓存中进行库存扣减
    库存扣减完成后，将下单请求发送到消息队列
    下单时再次校验实际库存，库存用完后，拦截所有请求，返回已售完
### 几个重要的点
#### 下单减库存
    当用户并发请求到达服务端时，首先创建订单，然后扣除库存，等待用户支付。这种顺序是我们一般人首先会想到的解决方案，这种情况下也能保证订单不会超卖，因为创建订单之后就会减库存，这是一个原子操作。但是这样也会产生一些问题，第一就是在极限并发情况下，任何一个内存操作的细节都至关影响性能，尤其像创建订单这种逻辑，一般都需要存储到磁盘数据库的，对数据库的压力是可想而知的；第二是如果用户存在恶意下单的情况，只下单不支付这样库存就会变少，会少卖很多订单，虽然服务端可以限制IP和用户的购买订单数量，这也不算是一个好方法。
#### 支付减库存
    如果等待用户支付了订单在减库存，第一感觉就是不会少卖。但是这是并发架构的大忌，因为在极限并发情况下，用户可能会创建很多订单，当库存减为零的时候很多用户发现抢到的订单支付不了了，这也就是所谓的“超卖”。也不能避免并发操作数据库磁盘IO
#### 预扣库存
    从上边两种方案的考虑，我们可以得出结论：只要创建订单，就要频繁操作数据库IO。那么有没有一种不需要直接操作数据库IO的方案呢，这就是预扣库存。先扣除了库存，保证不超卖，然后异步生成用户订单，这样响应给用户的速度就会快很多；那么怎么保证不少卖呢？用户拿到了订单，不支付怎么办？我们都知道现在订单都有有效期，比如说用户五分钟内不支付，订单就失效了，订单一旦失效，就会加入新的库存，这也是现在很多网上零售企业保证商品不少卖采用的方案。订单的生成是异步的,一般都会放到MQ、kafka这样的即时消费队列中处理,订单量比较少的情况下，生成订单非常快，用户几乎不用排队。
    业务系统中最常见的就是预扣库存方案，买家下单后，库存为其保留一定的时间(如 10 分 钟)，超过这个时间，库存将会自动释放，在买家付款 前，系统会校验该订单的库存是否还有保留:如果没有保留，则再次尝试预扣;如果库存 不足(也就是预扣失败)则不允许继续付款;如果预扣成功，则完成付款并实际地减去库存。
    秒杀商品采用“下单减库存”更加合
### 理论都会写，去尝试实现一个单机的扣库存demo
    //已实现，待优化更新,